{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# import gensim\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "from scipy import sparse\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time\n",
    "\n",
    "from attention import * \n",
    "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 100\n",
    "MAX_SENTS = 100 # this is the longest number of sentences in a document!!!\n",
    "MAX_NB_WORDS = 60000\n",
    "EMBEDDING_DIM = 300 #due to word2vec dimension!!! \n",
    "HIDDEN_SIZE = 50 #based on Yang et al CMU. (Hierachical Attention Networks for Document Classification)\n",
    "ATTENTION_SIZE = 100 #same as Yang et al. \n",
    "BATCH_SIZE = 50\n",
    "NUM_ITERS = 100\n",
    "DISPLAY_STEP = 10\n",
    "VALIDATION_STEP = 10\n",
    "TESTING_BATCH = 10\n",
    "USER_EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time of loading Word2Vec model:  101.50209975242615\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "# Download GoogleNews-vectors-negative300.bin.gz at \n",
    "#https://github.com/mmihaltz/word2vec-GoogleNews-vectors/blob/master/GoogleNews-vectors-negative300.bin.gz\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "toc = time.time()\n",
    "print(\"Running time of loading Word2Vec model: \", (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    \"\"\"Primitive batch generator \n",
    "    \"\"\"\n",
    "    size = X.shape[0]\n",
    "    X_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "    indices = np.arange(size)\n",
    "    np.random.shuffle(indices)\n",
    "    X_copy = X_copy[indices]\n",
    "    y_copy = y_copy[indices]\n",
    "    i=0\n",
    "\n",
    "    while True:\n",
    "        left, right = i*batch_size, (i+1)*batch_size\n",
    "        right = min(size, right)\n",
    "        yield X_copy[left:right], y_copy[left:right]\n",
    "        if right >= size:\n",
    "            i = 0\n",
    "            indices = np.arange(size)\n",
    "            X_copy = X_copy[indices]\n",
    "            y_copy = y_copy[indices]\n",
    "        else:\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer_based_on_training(train_folder, test_folder, dict_selected_words,\n",
    "                                   ground_truth_file='snopes_ground_truth.csv'):\n",
    "    '''Return tensor data of URL based solely on training interactions only!!!'''\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(ground_truth_file)\n",
    "    full = zip(df['snopes_page'], df['claim_label'])\n",
    "    dict_url_ground_truth = {}\n",
    "    for url, label in full:\n",
    "        assert label == True or label == False\n",
    "        if label == True:\n",
    "            dict_url_ground_truth[url] = 1\n",
    "        elif label == False:\n",
    "            dict_url_ground_truth[url] = 0\n",
    "        \n",
    "    assert len(dict_url_ground_truth) == 562\n",
    "    \n",
    "    def read_text_files(infolder):\n",
    "        documents = [fn for fn in listdir(infolder) if fn.endswith('.txt')]\n",
    "        data = np.zeros((len(documents), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "        dict_docs = {}\n",
    "        for fn in documents:\n",
    "            p = join(infolder, fn)\n",
    "            fin1 = open(p, 'r')\n",
    "            url = fin1.readline().replace('\\n', '')\n",
    "            assert 'http' in url\n",
    "            sents = []\n",
    "            for line in fin1:\n",
    "                sents.append(line.replace('\\n', ''))\n",
    "            dict_docs[url] = sents\n",
    "                \n",
    "        Y = []\n",
    "        for idx, url in enumerate(dict_docs.keys()):\n",
    "            assert 'http' in url\n",
    "            label = dict_url_ground_truth[url]\n",
    "            assert label == 0 or label == 1\n",
    "            Y.append([label, 1-label])\n",
    "            sentences = dict_docs[url]\n",
    "            for j, sent in enumerate(sentences):\n",
    "                if j < MAX_SENTS:\n",
    "                    wordTokens = text_to_word_sequence(sent)\n",
    "                    k = 0\n",
    "                    for _, word in enumerate(wordTokens):\n",
    "                        if word not in dict_selected_words:\n",
    "                            continue\n",
    "                        index_of_word = dict_selected_words[word]\n",
    "                        assert index_of_word >= 1 and index_of_word <= 16000\n",
    "                        if k < MAX_SENT_LENGTH:\n",
    "                            data[idx, j, k] = index_of_word\n",
    "                            k+=1\n",
    "                    \n",
    "        return data, np.array(Y)\n",
    "        \n",
    "    X_train, y_train = read_text_files(infolder=train_folder)\n",
    "    X_test, y_test = read_text_files(infolder=test_folder)\n",
    "    print(y_train.shape, \"here\")\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_content_text2num(selected_words_file='out_top_16K_words_file.txt'):\n",
    "    parent = \"train_test_data\"\n",
    "    dict_folds = {}\n",
    "    fin = open(selected_words_file, 'r')\n",
    "    cnt = 1\n",
    "    dict_selected_words = {}\n",
    "    for line in fin:\n",
    "        _, w, _ = line.split()\n",
    "        dict_selected_words[w] = cnt\n",
    "        cnt += 1\n",
    "    assert len(dict_selected_words) == 16000 and max(dict_selected_words.values()) == 16000\n",
    "    fin.close()\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        #########################################################\n",
    "        dict_words = {} #for stat\n",
    "        data_i = '%s/data_%s' % (parent, i)\n",
    "        train_folder = '%s/train' % data_i\n",
    "        test_folder = '%s/test' % data_i\n",
    "        X_train, y_train, X_test, y_test = fit_tokenizer_based_on_training(train_folder, test_folder, dict_selected_words)\n",
    "        dict_folds[i] = (X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    return dict_folds, dict_selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n"
     ]
    }
   ],
   "source": [
    "dict_folds, dict_selected_words = load_url_content_text2num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vocabs = 16000 \n",
    "'''Word2vec embedding matrix'''\n",
    "embedding_matrix = np.random.random((no_vocabs, EMBEDDING_DIM))\n",
    "#i starts at 1 not 0 like normal stuff!!!!\n",
    "for word, i in dict_selected_words.items(): \n",
    "    if word in word2vec.wv.vocab:\n",
    "        embedding_vector = word2vec[word]\n",
    "        embedding_matrix[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(true_labels, pred_labels):\n",
    "    assert y_true.shape == y_hat.shape\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))  \n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))  \n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))  \n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))  \n",
    "    #print 'TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN)\n",
    "    assert TP+ TN+ FP+ FN == len(true_labels)\n",
    "    return TP, TN, FP, FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0,0, 1, 1, 1, 0, 0, 0, 1, 0]) \n",
    "y_hat = np.array([0, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
    "print(computeMetrics(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamBiRNN(X_train, y_train, X_test, y_test, log_dir, outfile):\n",
    "        tf.reset_default_graph() \n",
    "        train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)\n",
    "        fout = open(outfile, 'w')\n",
    "        '''Variable with shape (no_vocabs, EMBEDDING_DIM) to get vectors in a sentence'''\n",
    "        embedding_matrix_variable = tf.Variable(embedding_matrix, trainable=True, dtype=tf.float32)\n",
    "        #print(embedding_matrix_variable.shape)\n",
    "        #print(X_train.shape)\n",
    "\n",
    "        '''We will take a bunch of sentences, where each sentence has length MAX_SENT_LENGTH\n",
    "        Ex: Two sentences: [[1,2,5,6,0], [3,5,3,6,0]] where numbers indicate a word. We will look up the \n",
    "        word vector for each word based on the number. \n",
    "        '''\n",
    "        #batch_sent_ph = tf.placeholder(tf.int32, [None, MAX_SENT_LENGTH]) \n",
    "        '''\n",
    "        Hope it work. After looking up, the shape should be \n",
    "        (batch_size, MAX_SENTS, MAX_SENT_LENGTH, EMBEDDING_DIM)\n",
    "        However, since we need to use bi_rnn and we learn representation of sentences first. \n",
    "        Therefore, we should use shape \n",
    "        (?, MAX_SENT_LENGTH, EMBEDDING_DIM) where \"?\" should be a multiple of MAX_SENTS\n",
    "        '''\n",
    "        batch_sent_ph = tf.placeholder(tf.int32, [None, MAX_SENT_LENGTH], name=\"batch_sent_ph\")\n",
    "        batch_sent_embedded = tf.nn.embedding_lookup(embedding_matrix_variable, batch_sent_ph)\n",
    "        y_ph = tf.placeholder(tf.float32, [None, 2], name=\"labels\")\n",
    "        sentence_length_ph = tf.placeholder(tf.int32, [None], name=\"sentence_length_ph\")\n",
    "        doc_actual_length_ph = tf.placeholder(tf.int32, [None], name=\"doc_actual_length_ph\")\n",
    "        #print(batch_sent_embedded)\n",
    "\n",
    "        '''We do not specify sequence_length. \n",
    "        Therefore, the number of GRU cell in forward (same as backward) is MAX_SENT_LENGTH'''\n",
    "        with tf.variable_scope(\"first_bi_rnn\"):\n",
    "            rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE), \n",
    "                                    inputs=batch_sent_embedded, \n",
    "                                    sequence_length=sentence_length_ph, \n",
    "                                    dtype=tf.float32)\n",
    "        with tf.name_scope(\"attention_first_bi_rnn\"):\n",
    "            attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True)\n",
    "        with tf.name_scope(\"dropout_afterfirst_bi_rnn\"):\n",
    "            dropout_first_bi_rnn = tf.nn.dropout(attention_output, keep_prob=0.8)\n",
    "        with tf.name_scope(\"sent_bedding_after_first_birnn\"):\n",
    "            sent_bedding_after_first_birnn = tf.reshape(dropout_first_bi_rnn, shape=[-1, MAX_SENTS, 2*HIDDEN_SIZE])\n",
    "        ###########second bi-rnn-layer ############################\n",
    "        with tf.variable_scope(\"second_bi_rnn\"):\n",
    "            bi_rnn_sent_outputs, _ = bi_rnn(GRUCell(2*HIDDEN_SIZE), GRUCell(2*HIDDEN_SIZE), \n",
    "                                            inputs=sent_bedding_after_first_birnn, \n",
    "                                            sequence_length=doc_actual_length_ph,\n",
    "                                            dtype=tf.float32)\n",
    "        with tf.name_scope(\"attention_second_bi_rnn\"):\n",
    "            attention_output2, alphas = attention(bi_rnn_sent_outputs, ATTENTION_SIZE, return_alphas=True)\n",
    "        with tf.name_scope(\"dropout_after_second_bi_rnn\"):\n",
    "            dropout_second_bi_rnn = tf.nn.dropout(attention_output2, keep_prob=0.8)\n",
    "\n",
    "        with tf.name_scope(\"FC_layer\"):\n",
    "            W = tf.Variable(tf.random_normal([HIDDEN_SIZE * 4, 2], stddev=0.1))\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "            y_hat = tf.matmul(dropout_second_bi_rnn, W) + b\n",
    "        #y_hat = tf.squeeze(y_hat)\n",
    "\n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            out_softmax = tf.nn.softmax(logits=y_hat)\n",
    "\n",
    "        with tf.name_scope(\"loss_cross_entropy\"):\n",
    "            loss = -tf.reduce_mean(tf.reduce_sum(tf.cast(y_ph, tf.float32) * tf.log(out_softmax), axis=1))\n",
    "        #loss = tf.reduce_sum(out_softmax)\n",
    "        A = tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "        with tf.variable_scope(\"Traininig\"):\n",
    "            train_step = tf.train.AdamOptimizer(1e-4).minimize(loss=loss)\n",
    "\n",
    "        with tf.variable_scope(\"evaluation\"):\n",
    "            ground_truth = tf.argmax(y_ph, 1)\n",
    "            predicted = tf.argmax(out_softmax, 1)\n",
    "            correct_prediction = tf.equal(predicted, ground_truth)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            accuracy_test = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        valVar = tf.Variable(0.0, \"valVar\")\n",
    "        valVal_ph = tf.placeholder(tf.float32, [], name=\"independent\")\n",
    "        update_valVar = valVar.assign(valVal_ph)\n",
    "        mySummary = tf.summary.scalar(\"Validation\", update_valVar)\n",
    "\n",
    "        B = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "        summary_op = tf.summary.merge([A, B])\n",
    "        #summary_op = tf.summary.merge_all()\n",
    "\n",
    "        #### Testing model phat ##########################\n",
    "        #TODO\n",
    "        pre_val_acc = -1\n",
    "        best_results = None\n",
    "        time_val_acc_reduced = 0\n",
    "\n",
    "        placeholder_input = (batch_sent_ph, y_ph, sentence_length_ph, doc_actual_length_ph)\n",
    "        STOP_TRAINING = False\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            saver.save(sess, 'saved_models/my_test_model')\n",
    "\n",
    "            writer = tf.summary.FileWriter(log_dir, graph=sess.graph)\n",
    "            cnt_step = 0\n",
    "            for i in range(NUM_ITERS):\n",
    "                num_batches = X_train.shape[0] / float(BATCH_SIZE)\n",
    "                num_batches = int(num_batches)\n",
    "                #num_batches = 11\n",
    "                if STOP_TRAINING:\n",
    "                    break\n",
    "                for b in range(num_batches):\n",
    "                    if STOP_TRAINING:\n",
    "                        break\n",
    "                    x_batch, y_batch = next(train_batch_generator)\n",
    "                    temp = np.sum(x_batch, axis=2)\n",
    "                    doc_actual_lengths_better = np.count_nonzero(temp, axis=1) \n",
    "\n",
    "                    #when reshaping data for feeddict, you should use np.reshape\n",
    "                    x_batch = x_batch.reshape(-1, MAX_SENT_LENGTH)\n",
    "                    '''Actual length of sentences in this batch_size * so_luong_sentence_moi_doc'''\n",
    "                    sentence_actual_lengths_better = np.count_nonzero(x_batch, axis=1)\n",
    "                    if cnt_step % DISPLAY_STEP == 0:\n",
    "                        #print(\"At iter %s and batch %s of %s - cntStep: %s\" % (i, b, num_batches, cnt_step))\n",
    "                        train_acc = accuracy.eval(feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n",
    "                                                           sentence_length_ph: sentence_actual_lengths_better,\n",
    "                                                           doc_actual_length_ph: doc_actual_lengths_better\n",
    "                                                           })\n",
    "                        print(\"Training accuracy at [iter %s][batch %s of %s][cntStep: %s] : %s\" % \n",
    "                              (i, b, num_batches, cnt_step, train_acc))\n",
    "                        fout.write('%s\\n' % \"Training accuracy at [iter %s][batch %s of %s][cntStep: %s] : %s\" % \n",
    "                              (i, b, num_batches, cnt_step, train_acc))\n",
    "                        fout.flush()\n",
    "                    ####################################################\n",
    "                    ### VALIDATION STEP TO AVOID OVERFITTING!!!!\n",
    "                    ########################################################\n",
    "                    if cnt_step % VALIDATION_STEP == 0:\n",
    "                        #do validation\n",
    "                        curr_val_acc, curr_fp, curr_fn = doValidation(X_data=X_test, y_data=y_test, curr_sess=sess,\n",
    "                                     metrics=[accuracy_test, ground_truth, predicted], \n",
    "                                                    batch_size=TESTING_BATCH, prefix=\"Validation\",\n",
    "                                    placeholder_input=placeholder_input)\n",
    "                        print(('Validation accuracy is: %s, fp:%s, fn:%s on shape %s' % \n",
    "                                             (curr_val_acc, curr_fp, curr_fn, str(X_test.shape))))\n",
    "                        fout.write('%s\\n' % ('Validation accuracy is: %s, fp:%s, fn:%s on shape %s' % \n",
    "                                             (curr_val_acc, curr_fp, curr_fn, str(X_test.shape))))\n",
    "                        fout.flush()\n",
    "                        _, ss = sess.run([update_valVar, mySummary], feed_dict={valVal_ph: curr_val_acc})\n",
    "                        writer.add_summary(ss, cnt_step)\n",
    "\n",
    "                        if curr_val_acc >= pre_val_acc:\n",
    "                            pre_val_acc = curr_val_acc\n",
    "                            time_val_acc_reduced = 0\n",
    "                            best_results = [curr_val_acc, curr_fp, curr_fn]\n",
    "#                         else:\n",
    "#                             time_val_acc_reduced +=1\n",
    "#                             if time_val_acc_reduced >= 10:\n",
    "#                                 #10 times accuracy reduced over time, we stop training!!!!\n",
    "#                                 print(\"Validation reduced!!! We should stop training here!!!!\")\n",
    "#                                 STOP_TRAINING = True\n",
    "\n",
    "                    #assert x_batch.shape == (BATCH_SIZE * MAX_SENTS, MAX_SENT_LENGTH), x_batch.shape\n",
    "                    summary, _ = sess.run([summary_op, train_step], \n",
    "                                                 feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n",
    "                                                           sentence_length_ph: sentence_actual_lengths_better,\n",
    "                                                           doc_actual_length_ph: doc_actual_lengths_better\n",
    "                                                           })\n",
    "                    writer.add_summary(summary, cnt_step)\n",
    "                    cnt_step += 1\n",
    "\n",
    "            writer.close()\n",
    "            #testing data\n",
    "            best_testing_acc = pre_val_acc\n",
    "            print('Best Testing accuracy is: ', best_testing_acc, ' on shape ', X_test.shape)\n",
    "            fout.write('%s\\n' % ('Best Testing ACC: %s, FP:%s, FN:%s on shape %s' % (best_results[0], best_results[1], \n",
    "                                                                                     best_results[2], str(X_test.shape))))\n",
    "            fout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(X_data, y_data, curr_sess, metrics, batch_size, prefix, placeholder_input):\n",
    "        accuracy, ground_truth, predicted = metrics\n",
    "        num_batches = X_data.shape[0] / float(batch_size)\n",
    "        num_batches = int(num_batches)\n",
    "        sum_acc, sum_fp, sum_fn, sum_TP, sum_TN = 0, 0, 0, 0, 0\n",
    "        cnt_rows = 0\n",
    "        batch_sent_ph, y_ph, sentence_length_ph, doc_actual_length_ph = placeholder_input\n",
    "        test_batch_generator = batch_generator(X_data, y_data, batch_size)\n",
    "        for i in range(num_batches+1):\n",
    "\n",
    "            x_batch, y_batch = next(test_batch_generator)\n",
    "            temp = np.sum(x_batch, axis=2)\n",
    "            #print(\"Test data shape: \", x_batch.shape)\n",
    "            doc_actual_lengths_test = np.count_nonzero(temp, axis=1) \n",
    "            x_batch_reshaped = x_batch.reshape(-1, MAX_SENT_LENGTH)\n",
    "            sentence_actual_lengths_test = np.count_nonzero(x_batch_reshaped, axis=1)\n",
    "            acc_result, true_labels, pred_labels = curr_sess.run([accuracy, ground_truth, predicted], \n",
    "                                                       feed_dict={batch_sent_ph: x_batch_reshaped, \n",
    "                                        y_ph: y_batch, sentence_length_ph: sentence_actual_lengths_test,\n",
    "                                        doc_actual_length_ph: doc_actual_lengths_test})\n",
    "            \n",
    "            tp_res, tn_res, fp_res, fn_res = computeMetrics(true_labels=true_labels, pred_labels=pred_labels)\n",
    "\n",
    "            assert abs(fp_res+tn_res+tp_res+fn_res - x_batch.shape[0]) < 1e-10, 'fp: %s, tn: %s, tp: %s, fn:%s vs. %s' % (fp_res, tn_res, tp_res, fn_res, x_batch.shape[0])\n",
    "            sum_acc += acc_result\n",
    "            sum_fp += fp_res\n",
    "            sum_fn += fn_res\n",
    "            sum_TP += tp_res\n",
    "            sum_TN += tn_res\n",
    "            #sum_fp += (fp_res/float(fp_res+tn_res))\n",
    "            #sum_fn += fn_res/float(tp_res+fn_res)\n",
    "            cnt_rows += x_batch.shape[0]\n",
    "        assert cnt_rows == X_data.shape[0], 'Mismatched rows_count: %s vs. %s' % (cnt_rows, X_data.shape[0])\n",
    "        rr = sum_acc/float(X_data.shape[0])\n",
    "        rr_fp = sum_fp/float(sum_fp+ sum_TN)\n",
    "        rr_fn = sum_fn/float(sum_TP+ sum_fn)\n",
    "        return rr, rr_fp, rr_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_BiGRU():\n",
    "    log_dir = \"HAM_log\"\n",
    "    \n",
    "\n",
    "    for key in dict_folds:\n",
    "        X_train, y_train, X_test, y_test = dict_folds[key]\n",
    "#         train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)\n",
    "#         test_batch_generator = batch_generator(X_test, y_test, TESTING_BATCH)\n",
    "\n",
    "        #clear log_dir\n",
    "        if os.path.exists(log_dir):\n",
    "            shutil.rmtree(log_dir)\n",
    "\n",
    "        hamBiRNN(X_train, y_train, X_test, y_test, log_dir, outfile='log_result_%s' % (key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy at [iter 0][batch 0 of 8][cntStep: 0] : 0.54\n",
      "Validation accuracy is: 0.5, fp:0.245614035088, fn:0.754385964912 on shape (114, 100, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-5d7943209fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_BiGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-7891ae79208f>\u001b[0m in \u001b[0;36mtrain_BiGRU\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhamBiRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log_result_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-c5a06b5759e9>\u001b[0m in \u001b[0;36mhamBiRNN\u001b[0;34m(X_train, y_train, X_test, y_test, log_dir, outfile)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                                  feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n\u001b[1;32m    161\u001b[0m                                                            \u001b[0msentence_length_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_actual_lengths_better\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                                            \u001b[0mdoc_actual_length_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_actual_lengths_better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                                                            })\n\u001b[1;32m    164\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_BiGRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(y_label='Percentage(%)'):\n",
    "    N = 3\n",
    "    fold1_best = {'acc': 0.754385964912, 'fp': 0.263157894737, 'fn': 0.228070175439}\n",
    "    fold2_best = {'acc': 0.710526315789, 'fp': 0.315789473684, 'fn': 0.263157894737}\n",
    "    fold3_best = {'acc': 0.728070175439, 'fp': 0.245614035088, 'fn': 0.298245614035}\n",
    "    fold4_best = {'acc': 0.675438596491, 'fp': 0.105263157895, 'fn': 0.543859649123}\n",
    "    fold5_best = {'acc': 0.684210526316, 'fp': 0.543859649123, 'fn': 0.0877192982456}\n",
    "\n",
    "    \n",
    "    folds = [fold1_best, fold2_best, fold3_best, fold4_best, fold5_best]\n",
    "    accs = np.array([e['acc'] for e in folds])*100\n",
    "    mean_acc, std_acc = np.mean(accs), np.std(accs)\n",
    "    \n",
    "    fprs = np.array([e['fp'] for e in folds]) * 100\n",
    "    mean_fp, std_fp = np.mean(fprs), np.std(fprs)\n",
    "    \n",
    "    fnrs = np.array([e['fn'] for e in folds]) * 100\n",
    "    mean_fn, std_fn = np.mean(fnrs), np.std(fnrs)\n",
    "    \n",
    "    ind = np.arange(N) # the x locations for the groups\n",
    "    width = 0.1  # the width of the bars\n",
    "    x = 1\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(1, mean_acc,width=0.2,color='#FF9F00',align='center', label='accuracy', yerr=std_acc, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    rects2 = ax.bar(2, mean_fp,width=0.2,color='#40FFBF',align='center', label='false positive rate', yerr=std_fp, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    rects3 = ax.bar(3, mean_fn,width=0.2,color='#800000',align='center', label='false negative rate', yerr=std_fn, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    print(\"Mean acc: \", mean_acc, \"Mean FP: \", mean_fp, \"Mean FN: \", mean_fn)\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel(y_label, fontsize=20)\n",
    "    # ax.set_title('Scores by group and gender')\n",
    "#     ax.set_xticks([\"acc\", \"fpr\", \"fnr\"])\n",
    "    ax.set_xlabel(\"Metrics\")\n",
    "#     plt.xticks(fontsize=50)\n",
    "#     plt.yticks(fontsize=50)\n",
    "\n",
    "    ax.set_xticklabels(('', '', ''))\n",
    "\n",
    "    ax.set_ylim(0, 100)\n",
    "    plt.legend((rects1[0], rects2[0], rects3[0]), ('Accuracy', 'FPR','FNR'), loc=1)\n",
    "    # plt.legend(loc)\n",
    "    plt.grid(True, linestyle='--', axis='y')\n",
    "    font = {'family': 'normal',\n",
    "            'size': 20}\n",
    "    plt.rc('font', **font)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acc:  71.0526315789 Mean FP:  29.4736842105 Mean FN:  28.4210526316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkvo/tensorflow3.5/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['normal'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0b811e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
