{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# import gensim\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "from scipy import sparse\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time\n",
    "\n",
    "from attention import * \n",
    "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 100\n",
    "MAX_SENTS = 100 # this is the longest number of sentences in a document!!!\n",
    "MAX_NB_WORDS = 60000\n",
    "EMBEDDING_DIM = 300 #due to word2vec dimension!!! \n",
    "HIDDEN_SIZE = 50 #based on Yang et al CMU. (Hierachical Attention Networks for Document Classification)\n",
    "ATTENTION_SIZE = 100 #same as Yang et al. \n",
    "BATCH_SIZE = 50\n",
    "NUM_ITERS = 100\n",
    "DISPLAY_STEP = 10\n",
    "VALIDATION_STEP = 10\n",
    "TESTING_BATCH = 10\n",
    "USER_EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time of loading Word2Vec model:  101.50209975242615\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "# Download GoogleNews-vectors-negative300.bin.gz at \n",
    "#https://github.com/mmihaltz/word2vec-GoogleNews-vectors/blob/master/GoogleNews-vectors-negative300.bin.gz\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "toc = time.time()\n",
    "print(\"Running time of loading Word2Vec model: \", (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    \"\"\"Primitive batch generator \n",
    "    \"\"\"\n",
    "    size = X.shape[0]\n",
    "    X_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "    indices = np.arange(size)\n",
    "    np.random.shuffle(indices)\n",
    "    X_copy = X_copy[indices]\n",
    "    y_copy = y_copy[indices]\n",
    "    i=0\n",
    "\n",
    "    while True:\n",
    "        left, right = i*batch_size, (i+1)*batch_size\n",
    "        right = min(size, right)\n",
    "        yield X_copy[left:right], y_copy[left:right]\n",
    "        if right >= size:\n",
    "            i = 0\n",
    "            indices = np.arange(size)\n",
    "            X_copy = X_copy[indices]\n",
    "            y_copy = y_copy[indices]\n",
    "        else:\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer_based_on_training(train_folder, test_folder, dict_selected_words,\n",
    "                                   ground_truth_file='snopes_ground_truth.csv'):\n",
    "    '''Return tensor data of URL based solely on training interactions only!!!'''\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(ground_truth_file)\n",
    "    full = zip(df['snopes_page'], df['claim_label'])\n",
    "    dict_url_ground_truth = {}\n",
    "    for url, label in full:\n",
    "        assert label == True or label == False\n",
    "        if label == True:\n",
    "            dict_url_ground_truth[url] = 1\n",
    "        elif label == False:\n",
    "            dict_url_ground_truth[url] = 0\n",
    "        \n",
    "    assert len(dict_url_ground_truth) == 562\n",
    "    \n",
    "    def read_text_files(infolder):\n",
    "        documents = [fn for fn in listdir(infolder) if fn.endswith('.txt')]\n",
    "        data = np.zeros((len(documents), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "        dict_docs = {}\n",
    "        for fn in documents:\n",
    "            p = join(infolder, fn)\n",
    "            fin1 = open(p, 'r')\n",
    "            url = fin1.readline().replace('\\n', '')\n",
    "            assert 'http' in url\n",
    "            sents = []\n",
    "            for line in fin1:\n",
    "                sents.append(line.replace('\\n', ''))\n",
    "            dict_docs[url] = sents\n",
    "                \n",
    "        Y = []\n",
    "        for idx, url in enumerate(dict_docs.keys()):\n",
    "            assert 'http' in url\n",
    "            label = dict_url_ground_truth[url]\n",
    "            assert label == 0 or label == 1\n",
    "            Y.append([label, 1-label])\n",
    "            sentences = dict_docs[url]\n",
    "            for j, sent in enumerate(sentences):\n",
    "                if j < MAX_SENTS:\n",
    "                    wordTokens = text_to_word_sequence(sent)\n",
    "                    k = 0\n",
    "                    for _, word in enumerate(wordTokens):\n",
    "                        if word not in dict_selected_words:\n",
    "                            continue\n",
    "                        index_of_word = dict_selected_words[word]\n",
    "                        assert index_of_word >= 1 and index_of_word <= 16000\n",
    "                        if k < MAX_SENT_LENGTH:\n",
    "                            data[idx, j, k] = index_of_word\n",
    "                            k+=1\n",
    "                    \n",
    "        return data, np.array(Y)\n",
    "        \n",
    "    X_train, y_train = read_text_files(infolder=train_folder)\n",
    "    X_test, y_test = read_text_files(infolder=test_folder)\n",
    "    print(y_train.shape, \"here\")\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_content_text2num(selected_words_file='out_top_16K_words_file.txt'):\n",
    "    parent = \"train_test_data\"\n",
    "    dict_folds = {}\n",
    "    fin = open(selected_words_file, 'r')\n",
    "    cnt = 1\n",
    "    dict_selected_words = {}\n",
    "    for line in fin:\n",
    "        _, w, _ = line.split()\n",
    "        dict_selected_words[w] = cnt\n",
    "        cnt += 1\n",
    "    assert len(dict_selected_words) == 16000 and max(dict_selected_words.values()) == 16000\n",
    "    fin.close()\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        #########################################################\n",
    "        dict_words = {} #for stat\n",
    "        data_i = '%s/data_%s' % (parent, i)\n",
    "        train_folder = '%s/train' % data_i\n",
    "        test_folder = '%s/test' % data_i\n",
    "        X_train, y_train, X_test, y_test = fit_tokenizer_based_on_training(train_folder, test_folder, dict_selected_words)\n",
    "        dict_folds[i] = (X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    return dict_folds, dict_selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n",
      "(448, 2) here\n"
     ]
    }
   ],
   "source": [
    "dict_folds, dict_selected_words = load_url_content_text2num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vocabs = 16000 \n",
    "'''Word2vec embedding matrix'''\n",
    "embedding_matrix = np.random.random((no_vocabs, EMBEDDING_DIM))\n",
    "#i starts at 1 not 0 like normal stuff!!!!\n",
    "for word, i in dict_selected_words.items(): \n",
    "    if word in word2vec.wv.vocab:\n",
    "        embedding_vector = word2vec[word]\n",
    "        embedding_matrix[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(true_labels, pred_labels):\n",
    "    assert y_true.shape == y_hat.shape\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))  \n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))  \n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))  \n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))  \n",
    "    #print 'TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN)\n",
    "    assert TP+ TN+ FP+ FN == len(true_labels)\n",
    "    return TP, TN, FP, FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0,0, 1, 1, 1, 0, 0, 0, 1, 0]) \n",
    "y_hat = np.array([0, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
    "print(computeMetrics(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamBiRNN(X_train, y_train, X_test, y_test, log_dir, outfile):\n",
    "        tf.reset_default_graph() \n",
    "        train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)\n",
    "        fout = open(outfile, 'w')\n",
    "        '''Variable with shape (no_vocabs, EMBEDDING_DIM) to get vectors in a sentence'''\n",
    "        embedding_matrix_variable = tf.Variable(embedding_matrix, trainable=True, dtype=tf.float32)\n",
    "        #print(embedding_matrix_variable.shape)\n",
    "        #print(X_train.shape)\n",
    "\n",
    "        '''We will take a bunch of sentences, where each sentence has length MAX_SENT_LENGTH\n",
    "        Ex: Two sentences: [[1,2,5,6,0], [3,5,3,6,0]] where numbers indicate a word. We will look up the \n",
    "        word vector for each word based on the number. \n",
    "        '''\n",
    "        #batch_sent_ph = tf.placeholder(tf.int32, [None, MAX_SENT_LENGTH]) \n",
    "        '''\n",
    "        Hope it work. After looking up, the shape should be \n",
    "        (batch_size, MAX_SENTS, MAX_SENT_LENGTH, EMBEDDING_DIM)\n",
    "        However, since we need to use bi_rnn and we learn representation of sentences first. \n",
    "        Therefore, we should use shape \n",
    "        (?, MAX_SENT_LENGTH, EMBEDDING_DIM) where \"?\" should be a multiple of MAX_SENTS\n",
    "        '''\n",
    "        batch_sent_ph = tf.placeholder(tf.int32, [None, MAX_SENT_LENGTH], name=\"batch_sent_ph\")\n",
    "        batch_sent_embedded = tf.nn.embedding_lookup(embedding_matrix_variable, batch_sent_ph)\n",
    "        y_ph = tf.placeholder(tf.float32, [None, 2], name=\"labels\")\n",
    "        sentence_length_ph = tf.placeholder(tf.int32, [None], name=\"sentence_length_ph\")\n",
    "        doc_actual_length_ph = tf.placeholder(tf.int32, [None], name=\"doc_actual_length_ph\")\n",
    "        #print(batch_sent_embedded)\n",
    "\n",
    "        '''We do not specify sequence_length. \n",
    "        Therefore, the number of GRU cell in forward (same as backward) is MAX_SENT_LENGTH'''\n",
    "        with tf.variable_scope(\"first_bi_rnn\"):\n",
    "            rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE), \n",
    "                                    inputs=batch_sent_embedded, \n",
    "                                    sequence_length=sentence_length_ph, \n",
    "                                    dtype=tf.float32)\n",
    "        with tf.name_scope(\"attention_first_bi_rnn\"):\n",
    "            attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True)\n",
    "        with tf.name_scope(\"dropout_afterfirst_bi_rnn\"):\n",
    "            dropout_first_bi_rnn = tf.nn.dropout(attention_output, keep_prob=0.8)\n",
    "        with tf.name_scope(\"sent_bedding_after_first_birnn\"):\n",
    "            sent_bedding_after_first_birnn = tf.reshape(dropout_first_bi_rnn, shape=[-1, MAX_SENTS, 2*HIDDEN_SIZE])\n",
    "        ###########second bi-rnn-layer ############################\n",
    "        with tf.variable_scope(\"second_bi_rnn\"):\n",
    "            bi_rnn_sent_outputs, _ = bi_rnn(GRUCell(2*HIDDEN_SIZE), GRUCell(2*HIDDEN_SIZE), \n",
    "                                            inputs=sent_bedding_after_first_birnn, \n",
    "                                            sequence_length=doc_actual_length_ph,\n",
    "                                            dtype=tf.float32)\n",
    "        with tf.name_scope(\"attention_second_bi_rnn\"):\n",
    "            attention_output2, alphas = attention(bi_rnn_sent_outputs, ATTENTION_SIZE, return_alphas=True)\n",
    "        with tf.name_scope(\"dropout_after_second_bi_rnn\"):\n",
    "            dropout_second_bi_rnn = tf.nn.dropout(attention_output2, keep_prob=0.8)\n",
    "\n",
    "        with tf.name_scope(\"FC_layer\"):\n",
    "            W = tf.Variable(tf.random_normal([HIDDEN_SIZE * 4, 2], stddev=0.1))\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "            y_hat = tf.matmul(dropout_second_bi_rnn, W) + b\n",
    "        #y_hat = tf.squeeze(y_hat)\n",
    "\n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            out_softmax = tf.nn.softmax(logits=y_hat)\n",
    "\n",
    "        with tf.name_scope(\"loss_cross_entropy\"):\n",
    "            loss = -tf.reduce_mean(tf.reduce_sum(tf.cast(y_ph, tf.float32) * tf.log(out_softmax), axis=1))\n",
    "        #loss = tf.reduce_sum(out_softmax)\n",
    "        A = tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "        with tf.variable_scope(\"Traininig\"):\n",
    "            train_step = tf.train.AdamOptimizer(1e-4).minimize(loss=loss)\n",
    "\n",
    "        with tf.variable_scope(\"evaluation\"):\n",
    "            ground_truth = tf.argmax(y_ph, 1)\n",
    "            predicted = tf.argmax(out_softmax, 1)\n",
    "            correct_prediction = tf.equal(predicted, ground_truth)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            accuracy_test = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        valVar = tf.Variable(0.0, \"valVar\")\n",
    "        valVal_ph = tf.placeholder(tf.float32, [], name=\"independent\")\n",
    "        update_valVar = valVar.assign(valVal_ph)\n",
    "        mySummary = tf.summary.scalar(\"Validation\", update_valVar)\n",
    "\n",
    "        B = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "        summary_op = tf.summary.merge([A, B])\n",
    "        #summary_op = tf.summary.merge_all()\n",
    "\n",
    "        #### Testing model phat ##########################\n",
    "        #TODO\n",
    "        pre_val_acc = -1\n",
    "        best_results = None\n",
    "        time_val_acc_reduced = 0\n",
    "\n",
    "        placeholder_input = (batch_sent_ph, y_ph, sentence_length_ph, doc_actual_length_ph)\n",
    "        STOP_TRAINING = False\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            saver.save(sess, 'saved_models/my_test_model')\n",
    "\n",
    "            writer = tf.summary.FileWriter(log_dir, graph=sess.graph)\n",
    "            cnt_step = 0\n",
    "            for i in range(NUM_ITERS):\n",
    "                num_batches = X_train.shape[0] / float(BATCH_SIZE)\n",
    "                num_batches = int(num_batches)\n",
    "                #num_batches = 11\n",
    "                if STOP_TRAINING:\n",
    "                    break\n",
    "                for b in range(num_batches):\n",
    "                    if STOP_TRAINING:\n",
    "                        break\n",
    "                    x_batch, y_batch = next(train_batch_generator)\n",
    "                    temp = np.sum(x_batch, axis=2)\n",
    "                    doc_actual_lengths_better = np.count_nonzero(temp, axis=1) \n",
    "\n",
    "                    #when reshaping data for feeddict, you should use np.reshape\n",
    "                    x_batch = x_batch.reshape(-1, MAX_SENT_LENGTH)\n",
    "                    '''Actual length of sentences in this batch_size * so_luong_sentence_moi_doc'''\n",
    "                    sentence_actual_lengths_better = np.count_nonzero(x_batch, axis=1)\n",
    "                    if cnt_step % DISPLAY_STEP == 0:\n",
    "                        #print(\"At iter %s and batch %s of %s - cntStep: %s\" % (i, b, num_batches, cnt_step))\n",
    "                        train_acc = accuracy.eval(feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n",
    "                                                           sentence_length_ph: sentence_actual_lengths_better,\n",
    "                                                           doc_actual_length_ph: doc_actual_lengths_better\n",
    "                                                           })\n",
    "                        print(\"Training accuracy at [iter %s][batch %s of %s][cntStep: %s] : %s\" % \n",
    "                              (i, b, num_batches, cnt_step, train_acc))\n",
    "                        fout.write('%s\\n' % \"Training accuracy at [iter %s][batch %s of %s][cntStep: %s] : %s\" % \n",
    "                              (i, b, num_batches, cnt_step, train_acc))\n",
    "                        fout.flush()\n",
    "                    ####################################################\n",
    "                    ### VALIDATION STEP TO AVOID OVERFITTING!!!!\n",
    "                    ########################################################\n",
    "                    if cnt_step % VALIDATION_STEP == 0:\n",
    "                        #do validation\n",
    "                        curr_val_acc, curr_fp, curr_fn = doValidation(X_data=X_test, y_data=y_test, curr_sess=sess,\n",
    "                                     metrics=[accuracy_test, ground_truth, predicted], \n",
    "                                                    batch_size=TESTING_BATCH, prefix=\"Validation\",\n",
    "                                    placeholder_input=placeholder_input)\n",
    "                        print(('Validation accuracy is: %s, fp:%s, fn:%s on shape %s' % \n",
    "                                             (curr_val_acc, curr_fp, curr_fn, str(X_test.shape))))\n",
    "                        fout.write('%s\\n' % ('Validation accuracy is: %s, fp:%s, fn:%s on shape %s' % \n",
    "                                             (curr_val_acc, curr_fp, curr_fn, str(X_test.shape))))\n",
    "                        fout.flush()\n",
    "                        _, ss = sess.run([update_valVar, mySummary], feed_dict={valVal_ph: curr_val_acc})\n",
    "                        writer.add_summary(ss, cnt_step)\n",
    "\n",
    "                        if curr_val_acc >= pre_val_acc:\n",
    "                            pre_val_acc = curr_val_acc\n",
    "                            time_val_acc_reduced = 0\n",
    "                            best_results = [curr_val_acc, curr_fp, curr_fn]\n",
    "#                         else:\n",
    "#                             time_val_acc_reduced +=1\n",
    "#                             if time_val_acc_reduced >= 10:\n",
    "#                                 #10 times accuracy reduced over time, we stop training!!!!\n",
    "#                                 print(\"Validation reduced!!! We should stop training here!!!!\")\n",
    "#                                 STOP_TRAINING = True\n",
    "\n",
    "                    #assert x_batch.shape == (BATCH_SIZE * MAX_SENTS, MAX_SENT_LENGTH), x_batch.shape\n",
    "                    summary, _ = sess.run([summary_op, train_step], \n",
    "                                                 feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n",
    "                                                           sentence_length_ph: sentence_actual_lengths_better,\n",
    "                                                           doc_actual_length_ph: doc_actual_lengths_better\n",
    "                                                           })\n",
    "                    writer.add_summary(summary, cnt_step)\n",
    "                    cnt_step += 1\n",
    "\n",
    "            writer.close()\n",
    "            #testing data\n",
    "            best_testing_acc = pre_val_acc\n",
    "            print('Best Testing accuracy is: ', best_testing_acc, ' on shape ', X_test.shape)\n",
    "            fout.write('%s\\n' % ('Best Testing ACC: %s, FP:%s, FN:%s on shape %s' % (best_results[0], best_results[1], \n",
    "                                                                                     best_results[2], str(X_test.shape))))\n",
    "            fout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(X_data, y_data, curr_sess, metrics, batch_size, prefix, placeholder_input):\n",
    "        accuracy, ground_truth, predicted = metrics\n",
    "        num_batches = X_data.shape[0] / float(batch_size)\n",
    "        num_batches = int(num_batches)\n",
    "        sum_acc, sum_fp, sum_fn, sum_TP, sum_TN = 0, 0, 0, 0, 0\n",
    "        cnt_rows = 0\n",
    "        batch_sent_ph, y_ph, sentence_length_ph, doc_actual_length_ph = placeholder_input\n",
    "        test_batch_generator = batch_generator(X_data, y_data, batch_size)\n",
    "        for i in range(num_batches+1):\n",
    "\n",
    "            x_batch, y_batch = next(test_batch_generator)\n",
    "            temp = np.sum(x_batch, axis=2)\n",
    "            #print(\"Test data shape: \", x_batch.shape)\n",
    "            doc_actual_lengths_test = np.count_nonzero(temp, axis=1) \n",
    "            x_batch_reshaped = x_batch.reshape(-1, MAX_SENT_LENGTH)\n",
    "            sentence_actual_lengths_test = np.count_nonzero(x_batch_reshaped, axis=1)\n",
    "            acc_result, true_labels, pred_labels = curr_sess.run([accuracy, ground_truth, predicted], \n",
    "                                                       feed_dict={batch_sent_ph: x_batch_reshaped, \n",
    "                                        y_ph: y_batch, sentence_length_ph: sentence_actual_lengths_test,\n",
    "                                        doc_actual_length_ph: doc_actual_lengths_test})\n",
    "            \n",
    "            tp_res, tn_res, fp_res, fn_res = computeMetrics(true_labels=true_labels, pred_labels=pred_labels)\n",
    "\n",
    "            assert abs(fp_res+tn_res+tp_res+fn_res - x_batch.shape[0]) < 1e-10, 'fp: %s, tn: %s, tp: %s, fn:%s vs. %s' % (fp_res, tn_res, tp_res, fn_res, x_batch.shape[0])\n",
    "            sum_acc += acc_result\n",
    "            sum_fp += fp_res\n",
    "            sum_fn += fn_res\n",
    "            sum_TP += tp_res\n",
    "            sum_TN += tn_res\n",
    "            #sum_fp += (fp_res/float(fp_res+tn_res))\n",
    "            #sum_fn += fn_res/float(tp_res+fn_res)\n",
    "            cnt_rows += x_batch.shape[0]\n",
    "        assert cnt_rows == X_data.shape[0], 'Mismatched rows_count: %s vs. %s' % (cnt_rows, X_data.shape[0])\n",
    "        rr = sum_acc/float(X_data.shape[0])\n",
    "        rr_fp = sum_fp/float(sum_fp+ sum_TN)\n",
    "        rr_fn = sum_fn/float(sum_TP+ sum_fn)\n",
    "        return rr, rr_fp, rr_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_BiGRU():\n",
    "    log_dir = \"HAM_log\"\n",
    "    \n",
    "\n",
    "    for key in dict_folds:\n",
    "        X_train, y_train, X_test, y_test = dict_folds[key]\n",
    "#         train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)\n",
    "#         test_batch_generator = batch_generator(X_test, y_test, TESTING_BATCH)\n",
    "\n",
    "        #clear log_dir\n",
    "        if os.path.exists(log_dir):\n",
    "            shutil.rmtree(log_dir)\n",
    "\n",
    "        hamBiRNN(X_train, y_train, X_test, y_test, log_dir, outfile='log_result_%s' % (key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy at [iter 0][batch 0 of 8][cntStep: 0] : 0.54\n",
      "Validation accuracy is: 0.5, fp:0.245614035088, fn:0.754385964912 on shape (114, 100, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-5d7943209fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_BiGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-7891ae79208f>\u001b[0m in \u001b[0;36mtrain_BiGRU\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhamBiRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log_result_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-c5a06b5759e9>\u001b[0m in \u001b[0;36mhamBiRNN\u001b[0;34m(X_train, y_train, X_test, y_test, log_dir, outfile)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                                  feed_dict={batch_sent_ph: x_batch, y_ph: y_batch,\n\u001b[1;32m    161\u001b[0m                                                            \u001b[0msentence_length_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_actual_lengths_better\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                                            \u001b[0mdoc_actual_length_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_actual_lengths_better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                                                            })\n\u001b[1;32m    164\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_BiGRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(y_label='Percentage(%)'):\n",
    "    N = 3\n",
    "    fold1_best = {'acc': 0.754385964912, 'fp': 0.263157894737, 'fn': 0.228070175439}\n",
    "    fold2_best = {'acc': 0.710526315789, 'fp': 0.315789473684, 'fn': 0.263157894737}\n",
    "    fold3_best = {'acc': 0.728070175439, 'fp': 0.245614035088, 'fn': 0.298245614035}\n",
    "    fold4_best = {'acc': 0.675438596491, 'fp': 0.105263157895, 'fn': 0.543859649123}\n",
    "    fold5_best = {'acc': 0.684210526316, 'fp': 0.543859649123, 'fn': 0.0877192982456}\n",
    "\n",
    "    \n",
    "    folds = [fold1_best, fold2_best, fold3_best, fold4_best, fold5_best]\n",
    "    accs = np.array([e['acc'] for e in folds])*100\n",
    "    mean_acc, std_acc = np.mean(accs), np.std(accs)\n",
    "    \n",
    "    fprs = np.array([e['fp'] for e in folds]) * 100\n",
    "    mean_fp, std_fp = np.mean(fprs), np.std(fprs)\n",
    "    \n",
    "    fnrs = np.array([e['fn'] for e in folds]) * 100\n",
    "    mean_fn, std_fn = np.mean(fnrs), np.std(fnrs)\n",
    "    \n",
    "    ind = np.arange(N) # the x locations for the groups\n",
    "    width = 0.1  # the width of the bars\n",
    "    x = 1\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(1, mean_acc,width=0.2,color='#FF9F00',align='center', label='accuracy', yerr=std_acc, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    rects2 = ax.bar(2, mean_fp,width=0.2,color='#40FFBF',align='center', label='false positive rate', yerr=std_fp, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    rects3 = ax.bar(3, mean_fn,width=0.2,color='#800000',align='center', label='false negative rate', yerr=std_fn, error_kw=dict(ecolor='black', lw=4, capsize=6, capthick=2))\n",
    "    print(\"Mean acc: \", mean_acc, \"Mean FP: \", mean_fp, \"Mean FN: \", mean_fn)\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel(y_label, fontsize=20)\n",
    "    # ax.set_title('Scores by group and gender')\n",
    "#     ax.set_xticks([\"acc\", \"fpr\", \"fnr\"])\n",
    "    ax.set_xlabel(\"Metrics\")\n",
    "#     plt.xticks(fontsize=50)\n",
    "#     plt.yticks(fontsize=50)\n",
    "\n",
    "    ax.set_xticklabels(('', '', ''))\n",
    "\n",
    "    ax.set_ylim(0, 100)\n",
    "    plt.legend((rects1[0], rects2[0], rects3[0]), ('Accuracy', 'FPR','FNR'), loc=1)\n",
    "    # plt.legend(loc)\n",
    "    plt.grid(True, linestyle='--', axis='y')\n",
    "    font = {'family': 'normal',\n",
    "            'size': 20}\n",
    "    plt.rc('font', **font)\n",
    "#     plt.savefig('fig1_birnn_result.png', bbox_inches='tight')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkvo/tensorflow3.5/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['normal'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0a0084198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
